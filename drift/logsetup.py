# -*- coding: utf-8 -*-
"""
    drift - Logging setup code
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    Set up logging based on config dict.

    :copyright: (c) 2014 CCP
"""
import logging
import logging.handlers
import logging.config
import json
import datetime
import os
import os.path
from random import getrandbits
from socket import gethostname
from collections import OrderedDict

from flask import g, request

class TimedRotatingFileHandler(logging.handlers.TimedRotatingFileHandler):
    """
    Extending TimedRotatingFileHandler so that 'filename' is automatically
    generated by taking into account the 'log_folder' property of 'logging'
    config. This also enables a work-around for the 'doRollover' issue.
    """
    log_folder = None

    def __init__(self, *args, **kw):
        if not self.log_folder:
            #self.log_folder = os.path.abspath(os.path.join(__file__, "../../logs"))
            from drift.appmodule import app
            self.log_folder = os.path.join(app.instance_path, "../logs")

        # Make sure the log folder exists.
        if not os.path.exists(self.log_folder):
            os.makedirs(self.log_folder)

        # Generate a unique id so we won't get doRollover crash on Windows.
        logname = kw.get("filename", "unnamed")
        timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        filename = "{}.{}".format(logname, timestamp)
        n = 0
        # prevent clashes
        while os.path.exists(os.path.join(self.log_folder, filename + ".log")):
            n += 1
            filename = "{}.{}-{}".format(logname, timestamp, n)
        filename = os.path.join(self.log_folder, filename) + ".log"
        kw["filename"] = filename
        kw["delay"] = True
        super(TimedRotatingFileHandler, self).__init__(*args, **kw)


class JSONFormatter(logging.Formatter):
    """
    Format log message as JSON.
    """
    source_host = gethostname()

    def __init__(self):
        super(JSONFormatter, self).__init__()

    def formatTime(self, record, datefmt=None):
        dt = datetime.datetime.fromtimestamp(record.created)
        return dt.isoformat() + "Z"

    def format(self, record):
        message = super(JSONFormatter, self).format(record)

        field_names = "levelname", "levelno", "process", "thread", "name", \
            "filename", "module", "funcName", "lineno"

        data = OrderedDict()
        data["timestamp"] = self.formatTime(record) # put the timestamp first for splunk timestamp indexing
        tenant = None
        remote_addr = None
        try:
            remote_addr = request.remote_addr
        except Exception:
           pass
        try:
            tenant = g.ccpenv["name"]
        except Exception:
            pass
        try:
            for k, v in g.jwt.iteritems():
                key = "jwt-{}".format(k)
                data[key] = v
        except Exception:
            pass

        data["tenant"] = tenant
        data["remote_addr"] = remote_addr

        data["message"] = message
        data.update({
            key: getattr(record, key)
            for key in field_names
            if hasattr(record, key)
        })

        # add "bs-XXX" request headers to the logs
        try:
            for header in sorted(request.headers):
                k = header[0].lower()
                v = header[1]
                if k.startswith("bs-"):
                    try:
                        v = int(v)
                    except:
                        try:
                            v = str(v)
                        except:
                            pass
                    data[k] = v
        except Exception as e:
            pass

        json_text = json.dumps(data, default=self._json_default)
        return json_text

    @staticmethod
    def _json_default(obj):
        """
        Coerce everything to strings.
        All objects representing time get output as ISO8601.
        """
        if isinstance(obj, datetime.datetime) or \
           isinstance(obj, datetime.date) or \
           isinstance(obj, datetime.time):
            return obj.isoformat()
        else:
            return str(obj)


class EventLogFormatter(logging.Formatter):
    """
    Format log message as EventLog JSON.
    """
    def __init__(self):
        super(EventLogFormatter, self).__init__()

    def formatTime(self, record, datefmt=None):
        dt = datetime.datetime.fromtimestamp(record.created)
        return dt.strftime("%Y.%m.%d %H:%M:%S.%f")

    def format(self, record):
        message = super(EventLogFormatter, self).format(record)

        field_names = []
        data = OrderedDict()

        data["dateTime"] = self.formatTime(record)
        data["eventName"] = message
        data["pilot_id"] = getattr(record, "pilot_id", None)

        for col in record.__dict__:
            if col.startswith("eventlog_"):
                key = col[9:]
                data[key] = getattr(record, col)

        json_text = json.dumps(data, default=self._json_default)
        return json_text

    @staticmethod
    def _json_default(obj):
        """
        Coerce everything to strings.
        All objects representing time get output as ISO8601.
        """
        if isinstance(obj, datetime.datetime) or \
           isinstance(obj, datetime.date) or \
           isinstance(obj, datetime.time):
            return obj.isoformat()
        else:
            return str(obj)


# Calling 'logsetup' more than once may result in multiple handlers emitting
# multiple log events for a single log call. Flagging it is a simple fix.
_setup_done = False


def logsetup(app):

    global _setup_done
    if _setup_done:
        return
    _setup_done = True

    if "logging" not in app.config:
        return

    # Install console handler
    stream_handler = logging.StreamHandler()
    stream_handler.name = "console"
    stream_formatter = logging.Formatter(
        fmt="'%(asctime)s %(levelname)-8s %(name)-15s %(message)s'")
    stream_handler.setFormatter(stream_formatter)
    logging.root.addHandler(stream_handler)

    config = app.config["logging"]

    # Install log file handler
    handlers_config = config.get("handlers", {}).get("logfile", {})
    TimedRotatingFileHandler.log_folder = config.get("log_folder", "")
    file_handler = TimedRotatingFileHandler(
        filename=handlers_config.get("filename", "logfile"),
        when=handlers_config.get("when", "D"),
        interval=handlers_config.get("interval", 1),
    )
    file_handler.name = "logfile"
    file_handler.setFormatter(JSONFormatter())
    logging.root.addHandler(file_handler)

    # Install eventLog file handler
    handlers_config = config.get("handlers", {}).get("eventlogfile", {})
    TimedRotatingFileHandler.log_folder = config.get("event_log_folder", "")
    file_handler = TimedRotatingFileHandler(
        filename=handlers_config.get("filename", "eventlog"),
        when=handlers_config.get("when", "H"),
        interval=handlers_config.get("interval", 1),
    )
    file_handler.name = "eventlogfile"
    file_handler.setFormatter(EventLogFormatter())
    l = logging.getLogger("eventLog")
    l.addHandler(file_handler)

    # Apply additional 'level' and 'propagate' settings for handlers and
    # loggers. Note that two handlers have been pre-defined now, the 'console'
    # and 'logfile' handlers.
    logging.config.dictConfig(config)


def logsetup_post(app):
    for logger_name, settings in app.config.get("loggers", {}).items():
        log = logging.getLogger(logger_name)
        if "level" in settings:
            log.setLevel(settings["level"])